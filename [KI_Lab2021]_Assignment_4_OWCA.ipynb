{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[KI-Lab2021] Assignment 4 OWCA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyManyqOqJgXJBUrGaAk7EvA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jufabeck2202/KI-Lab/blob/main/%5BKI_Lab2021%5D_Assignment_4_OWCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJKIoo8F5Ijw"
      },
      "source": [
        "Overview:\n",
        "\n",
        "• In this assignment we want to build a model that can generate German nouns\n",
        "given a prefix as input.\n",
        "Example: Input „Jahr\" → Output: „Jahrmarkt“ .\n",
        "\n",
        "• For this purpose, we load German language data and filter it for nouns with spaCy.\n",
        "\n",
        "• We then use a simple RNN to learn to generated names.\n",
        "\n",
        "• In a second step, we switch to a more sophisticated LSTM model and compare the\n",
        "results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1NxUrjP5T12"
      },
      "source": [
        "1. Go to the following Git repo which contains a dataset of German articles:\n",
        "https://github.com/tblock/10kGNAD\n",
        "2. Download the file train.csv\tfrom there and import it into a notebook.\n",
        "3. Drop the label and only use the sentence in each line (the part after the first ; ).\n",
        "4. Use spaCy to get all nouns in the whole file.\n",
        "5. Filter out the nouns that have characters wich are not in all_letters (see\n",
        "code snippet below). The remaining set of nouns constitute our training data.\n",
        "6. Go through the PyTorch tutorial on name generation. Clone the notebook, execute it\n",
        "and understand what is going on.\n",
        "7. Use the same architecture to train a language model on the nouns that were extracted\n",
        "from the German dataset in step 1 to 5. (Note: We do not need a „category“, you have\n",
        "to remove everything that belongs to „category“ from the code).\n",
        "8. Extend the sampling logic in the sample function sucht that:\n",
        "  \n",
        "  i. The model extends any given prefix string by first feeding the prefix into the RNN\n",
        "and then start generating new characters. (Currently the model only samples based\n",
        "on a given starting letter).\n",
        "  \n",
        "  ii. Currently the model uses the highest score during sampling. Change that into\n",
        "drawing a real sample from the softmax distribution.\n",
        "9. Choose 10 random words from the training data and randomly cut-off a prefix. For\n",
        "every of those prefixes give an output for:\n",
        "  1. The model extending the prefix with the max score approach.\n",
        "  2. The mode extending the prefix with a real sampling approach.\n",
        "  3. Randomly pick characters from all_letters to extend the prefix (this is just for\n",
        "comparison reasons, i.e. how would a complete random generation look like).\n",
        "Bonus task (which will be very helpful for the next assignment):\n",
        "• Use an LSTM as described here (but without the embeddings) to train the model.\n",
        "• Feed the whole word at once to the LSTM (i.e. not a single characters at a time).\n",
        "• Generate some words to see the results\n",
        "\n",
        "Do not expect the models to generate always meaningful words. The model should\n",
        "output words that are in some sense similar to valid words and which look much closer\n",
        "to real words than randomly generated output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psGdscU35EmT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}